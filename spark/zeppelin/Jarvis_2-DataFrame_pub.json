{"paragraphs":[{"text":"%md\n# Creating Dataframes\n\nSpark DF allows you to create dataframes from the following sources.\n\n- Option 1: Spark Sequence (built-in data structure)\n- Option 2: External sources\n    - Hive tables (connect to Hive metastore)\n    - Structured and semi-structured files from different file systems (e.g., HDFS, GS, S3, local FS)","user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Creating Dataframes</h1>\n<p>Spark DF allows you to create dataframes from the following sources.</p>\n<ul>\n  <li>Option 1: Spark Sequence (built-in data structure)</li>\n  <li>Option 2: External sources\n    <ul>\n      <li>Hive tables (connect to Hive metastore)</li>\n      <li>Structured and semi-structured files from different file systems (e.g., HDFS, GS, S3, local FS)</li>\n    </ul>\n  </li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084965_166413070","id":"20200119-073223_398987810","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:334"},{"text":"%md\n## Option 1: Spark Sequence\n\nSpark DF can convert a sequence of tuples to Spark DF.\ne.g., `Seq[(String, Double, String, String)]`\n\n- A tuple corresponds to a DF row.\n- An element in a tuple corresponds to a column to a particular row.\n\nPlease run and learn the paragraph below. Feel free to modify the code to test your queries.","user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Option 1: Spark Sequence</h2>\n<p>Spark DF can convert a sequence of tuples to Spark DF.<br/>e.g., <code>Seq[(String, Double, String, String)]</code></p>\n<ul>\n  <li>A tuple corresponds to a DF row.</li>\n  <li>An element in a tuple corresponds to a column to a particular row.</li>\n</ul>\n<p>Please run and learn the paragraph below. Feel free to modify the code to test your queries.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084966_1760579383","id":"20190519-201210_1157722001","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:335"},{"text":"%md\n### Scala Implicit Conversions (optional)\n\nIn short, you have to `import spark.implicits._` to convert/cast a `Seq[(String, Double, String, String)]` to a Spark `DataFrame`. (e.g. `lineTupleSeq.toDF`)\n\nThis is called implicit conversions in Scala. In this case, `spark.implicits.localSeqToDatasetHolder` creates a Dataset from a local Seq.\n\nSpark Scala Docs:\n\n- <a href=\"https://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.sql.SparkSession$implicits$@localSeqToDatasetHolder[T](s:Seq[T])(implicitevidence$7:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.DatasetHolder[T]\" target=\"_blank\">implicits.localSeqToDatasetHolder</a>\n- <a href=\"http://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.sql.DatasetHolder@toDF(colNames:String*):org.apache.spark.sql.DataFrame\" target=\"_blank\">DatasetHolder</a>","user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Scala Implicit Conversions (optional)</h3>\n<p>In short, you have to <code>import spark.implicits._</code> to convert/cast a <code>Seq[(String, Double, String, String)]</code> to a Spark <code>DataFrame</code>. (e.g. <code>lineTupleSeq.toDF</code>)</p>\n<p>This is called implicit conversions in Scala. In this case, <code>spark.implicits.localSeqToDatasetHolder</code> creates a Dataset from a local Seq.</p>\n<p>Spark Scala Docs:</p>\n<ul>\n  <li>\n  <a href=\"https://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.sql.SparkSession$implicits$@localSeqToDatasetHolder[T](s:Seq[T])(implicitevidence$7:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.DatasetHolder[T]\" target=\"_blank\">implicits.localSeqToDatasetHolder</a></li>\n  <li>\n  <a href=\"http://spark.apache.org/docs/2.3.0/api/scala/index.html#org.apache.spark.sql.DatasetHolder@toDF(colNames:String*):org.apache.spark.sql.DataFrame\" target=\"_blank\">DatasetHolder</a></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084967_-1721532179","id":"20190520-102917_1809142825","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:336"},{"text":"/**\n * Each line/record/row must be a Tuple\n * e.g.  Tuple(AAPL,110.5,2018-02-01,Apple)\n * \n * Lines are grouped into a Seq\n * List(\n *   (AAPL,110.5,2018-02-01,Apple),\n *   (AMZN,1500.52,2018-02-01,Ammazon.com),\n *   (FB,170.01,2018-02-01,Facebook)\n * )\n */\nval lineTuple1 = (\"AAPL\",110.5,\"2018-02-01\",\"Apple\")\nval lineTuple2 = (\"AMZN\",1500.52,\"2018-02-01\",\"Ammazon.com\")\nval lineTuple3 = (\"FB\",170.01,\"2018-02-01\",\"Facebook\")\nval lineTupleSeq = Seq(lineTuple1,lineTuple2,lineTuple3)\n\n//To use toDF, you must import this (see next section for details)\n//In fact Zeppellin interpreter already imported this for you\nimport spark.implicits._\nval stockDf = lineTupleSeq.toDF(\"ticker\",\"price\", \"date\", \"companyName\")\nprintln(\">>Print Schema\")\nstockDf.printSchema\n\n//SELECT * FROM stock LIMIT 3\nprintln(\">>Print 3 rows\")\nstockDf.show(3)\n\n//SELECT companyName AS company_name, price FROM stock\nprintln(\">>Print all rows with renamed columns\")\nstockDf.select(col(\"companyName\").as(\"company_name\"), col(\"price\")).show()\n\n//Use SQL to query dataframe\n//creating a temp view\nstockDf.createOrReplaceTempView(\"stock\")\n//execute query\nval filteredDf = spark.sql(\"SELECT * FROM stock WHERE price > 100.0\")\nprintln(\">>SQL\")\nfilteredDf.show()\n\n","user":"anonymous","dateUpdated":"2020-03-23T13:55:06+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lineTuple1: (String, Double, String, String) = (AAPL,110.5,2018-02-01,Apple)\nlineTuple2: (String, Double, String, String) = (AMZN,1500.52,2018-02-01,Ammazon.com)\nlineTuple3: (String, Double, String, String) = (FB,170.01,2018-02-01,Facebook)\nlineTupleSeq: Seq[(String, Double, String, String)] = List((AAPL,110.5,2018-02-01,Apple), (AMZN,1500.52,2018-02-01,Ammazon.com), (FB,170.01,2018-02-01,Facebook))\nimport spark.implicits._\nstockDf: org.apache.spark.sql.DataFrame = [ticker: string, price: double ... 2 more fields]\n>>Print Schema\nroot\n |-- ticker: string (nullable = true)\n |-- price: double (nullable = false)\n |-- date: string (nullable = true)\n |-- companyName: string (nullable = true)\n\n>>Print 3 rows\n+------+-------+----------+-----------+\n|ticker|  price|      date|companyName|\n+------+-------+----------+-----------+\n|  AAPL|  110.5|2018-02-01|      Apple|\n|  AMZN|1500.52|2018-02-01|Ammazon.com|\n|    FB| 170.01|2018-02-01|   Facebook|\n+------+-------+----------+-----------+\n\n>>Print all rows with renamed columns\n+------------+-------+\n|company_name|  price|\n+------------+-------+\n|       Apple|  110.5|\n| Ammazon.com|1500.52|\n|    Facebook| 170.01|\n+------------+-------+\n\nfilteredDf: org.apache.spark.sql.DataFrame = [ticker: string, price: double ... 2 more fields]\n>>SQL\n+------+-------+----------+-----------+\n|ticker|  price|      date|companyName|\n+------+-------+----------+-----------+\n|  AAPL|  110.5|2018-02-01|      Apple|\n|  AMZN|1500.52|2018-02-01|Ammazon.com|\n|    FB| 170.01|2018-02-01|   Facebook|\n+------+-------+----------+-----------+\n\n"}]},"apps":[],"jobName":"paragraph_1584860084967_-702761100","id":"20190519-201416_412351679","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T13:55:07+0000","dateFinished":"2020-03-23T13:56:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:337"},{"text":"%md\n## Option 2: External sources\nThe most common way to create Spark DFs is to read data/files from external sources. Spark has built-in features to parse CSV, JSON, and many other semistructured and structured files.\n\nPlease run and learn the paragraph below. Feel free to modify the code to test your queries.","user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Option 2: External sources</h2>\n<p>The most common way to create Spark DFs is to read data/files from external sources. Spark has built-in features to parse CSV, JSON, and many other semistructured and structured files.</p>\n<p>Please run and learn the paragraph below. Feel free to modify the code to test your queries.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084967_288016","id":"20190520-104920_1833330750","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:338"},{"text":"//Read CSV file to df\n//local or hdfs path\nval path = \"/user/manpreetk0294/datasets/online_retail/online-retail-dataset.csv\"\n\n//spark.read is able to handle csv formats\nval retailDf = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(path)\n\nretailDf.printSchema\nretailDf.show(3)\nretailDf.show(3,false)","user":"anonymous","dateUpdated":"2020-03-23T13:56:47+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"path: String = /user/manpreetk0294/datasets/online_retail/online-retail-dataset.csv\nretailDf: org.apache.spark.sql.DataFrame = [InvoiceNo: string, StockCode: string ... 6 more fields]\nroot\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: string (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- Country: string (nullable = true)\n\n+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\nonly showing top 3 rows\n\n+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\n|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate   |UnitPrice|CustomerID|Country       |\n+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\n|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|6       |12/1/2010 8:26|2.55     |17850     |United Kingdom|\n|536365   |71053    |WHITE METAL LANTERN               |6       |12/1/2010 8:26|3.39     |17850     |United Kingdom|\n|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER    |8       |12/1/2010 8:26|2.75     |17850     |United Kingdom|\n+---------+---------+----------------------------------+--------+--------------+---------+----------+--------------+\nonly showing top 3 rows\n\n"}]},"apps":[],"jobName":"paragraph_1584860084968_-2033744982","id":"20190520-095229_630927102","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T13:56:47+0000","dateFinished":"2020-03-23T13:57:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:339"},{"text":"%md\n### Column Type Cast\nIn the previous paragraph, the data type of the `InvoiceDate` column is String instead of `timestamp`. In this practice, you need to cast `InvoiceDate` column to Spark `timestamp` data type.\n\n```bash\nresultDf.printSchema\nroot\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: timestamp (nullable = true) #cast string to timestamp\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- Country: string (nullable = true)\n```\n","user":"anonymous","dateUpdated":"2020-03-23T13:59:04+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Column Type Cast</h3>\n<p>In the previous paragraph, the data type of the <code>InvoiceDate</code> column is String instead of <code>timestamp</code>. In this practice, you need to cast <code>InvoiceDate</code> column to Spark <code>timestamp</code> data type.</p>\n<pre><code class=\"bash\">resultDf.printSchema\nroot\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: timestamp (nullable = true) #cast string to timestamp\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- Country: string (nullable = true)\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084968_-1436653978","id":"20190520-085947_2007764287","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T13:59:04+0000","dateFinished":"2020-03-23T13:59:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:340"},{"text":"//write code to cast InvoiceData from String to timestamp\n//save the result DF as `val restailCastDf`\n//please see sample result at the end of this paragraph (below the editor)\n\nval retailCastDf = retailDf.select(col(\"InvoiceNo\"),col(\"StockCode\"),col(\"Description\"),col(\"Quantity\"),col(\"UnitPrice\"),col(\"CustomerID\"),col(\"Country\"),to_timestamp(col(\"InvoiceDate\"),\"MM/dd/yyyy HH:mm\").alias(\"InvoiceDate\"))\n\n\n//print schema\nretailCastDf.printSchema\n//print rows to verify\nretailCastDf.show(3)\n//Cache DF in memory since it will be accessed frequently\nretailCastDf.cache","user":"anonymous","dateUpdated":"2020-03-23T16:38:38+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"retailCastDf: org.apache.spark.sql.DataFrame = [InvoiceNo: string, StockCode: string ... 6 more fields]\nroot\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- Country: string (nullable = true)\n |-- InvoiceDate: timestamp (nullable = true)\n\n+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+\n|InvoiceNo|StockCode|         Description|Quantity|UnitPrice|CustomerID|       Country|        InvoiceDate|\n+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|     2.55|     17850|United Kingdom|2010-12-01 08:26:00|\n|   536365|    71053| WHITE METAL LANTERN|       6|     3.39|     17850|United Kingdom|2010-12-01 08:26:00|\n|   536365|   84406B|CREAM CUPID HEART...|       8|     2.75|     17850|United Kingdom|2010-12-01 08:26:00|\n+---------+---------+--------------------+--------+---------+----------+--------------+-------------------+\nonly showing top 3 rows\n\nres163: retailCastDf.type = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"}]},"apps":[],"jobName":"paragraph_1584860084968_-275019902","id":"20190519-215300_721200493","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T16:38:38+0000","dateFinished":"2020-03-23T16:38:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:341"},{"text":"%md\n# DF Operations","user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>DF Operations</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084968_589840103","id":"20191010-103454_2098588366","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:342"},{"text":"%md\n## DataFrame SELECT\nImplement the following SQL queries using dataframe. Compare different select syntax.\n\n```sql\nSELECT *\nFROM retail\nLIMIT 3\n\nSELECT InvoiceNo\nFROM retail\n\nSELECT InvoiceNo as invoiceNo\nFROM retail\n\nSELECT max(UnitPrice) as max_unit_price\nFROM retail\n```","user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataFrame SELECT</h2>\n<p>Implement the following SQL queries using dataframe. Compare different select syntax.</p>\n<pre><code class=\"sql\">SELECT *\nFROM retail\nLIMIT 3\n\nSELECT InvoiceNo\nFROM retail\n\nSELECT InvoiceNo as invoiceNo\nFROM retail\n\nSELECT max(UnitPrice) as max_unit_price\nFROM retail\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084969_477997906","id":"20190519-221054_1925024171","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:343"},{"text":"//SELECT * from retail limit 1;\nretailCastDf.show(1)\nimport org.apache.spark.sql.functions._\n\n//select InvoiceNo,CustomerID,Country from retail limit 1;\nretailCastDf.select(\"InvoiceNo\").show(1)\n\n//Different ways of select \nretailCastDf.select($\"InvoiceNo\").show(1)\nretailCastDf.select('InvoiceNo).show(1)\nretailCastDf.select(col(\"InvoiceNo\")).show(1)\nretailCastDf.select(retailCastDf.col(\"InvoiceNo\")).show(1)\nretailCastDf.select(expr(\"InvoiceNo\")).show(1)\n\n//ERROR: cannot mix \n//retailCastDf.select($\"InvoiceNo\", \"StockCode\").show(1)\n\n//expr or selectExpr is most powerful and close to SQL syntax\n//SELECT InvoiceNo as invoiceId from retail limit 1;\n//col(\"InvoiceNo\").as(\"invoiceId\")\nretailCastDf.select(expr(\"InvoiceNo as invoiceId\")).show(1)\nretailCastDf.selectExpr(\"InvoiceNo as invoiceId\").show(1)\n\n//SELECT * from retail limit 1;\nretailCastDf.selectExpr(\"*\").show(1)\n\n//select max(UnitPrice) as maxUnitPrice from retail\nretailCastDf.selectExpr(\"max(UnitPrice) as maxUnitPrice\").show \n","user":"anonymous","dateUpdated":"2020-03-23T16:26:29+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\n|InvoiceNo|StockCode|         Description|Quantity|UnitPrice|CustomerID|       Country|to_timestamp(`InvoiceDate`, 'MM/dd/yyyy HH:mm')|\n+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|     2.55|     17850|United Kingdom|                            2010-12-01 08:26:00|\n+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\nonly showing top 1 row\n\nimport org.apache.spark.sql.functions._\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|InvoiceNo|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|invoiceId|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+\n|invoiceId|\n+---------+\n|   536365|\n+---------+\nonly showing top 1 row\n\n+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\n|InvoiceNo|StockCode|         Description|Quantity|UnitPrice|CustomerID|       Country|to_timestamp(`InvoiceDate`, 'MM/dd/yyyy HH:mm')|\n+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|     2.55|     17850|United Kingdom|                            2010-12-01 08:26:00|\n+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\nonly showing top 1 row\n\n+------------+\n|maxUnitPrice|\n+------------+\n|     38970.0|\n+------------+\n\n"}]},"apps":[],"jobName":"paragraph_1584860084969_755069632","id":"20190519-211701_1956303781","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T16:26:29+0000","dateFinished":"2020-03-23T16:26:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:344"},{"text":"%md\n## DataFrame filtering (WHERE)\n\nImplement the following SQL query\n\n```sql\nSELECT *\nFROM retail\nWHERE InvoiceNo = 536365\nLIMIT 2\n```\n\nSample results\n```\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|     17850|United Kingdom|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nonly showing top 2 rows\n```","user":"anonymous","dateUpdated":"2020-03-23T14:17:39+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>DataFrame filtering (WHERE)</h2>\n<p>Implement the following SQL query</p>\n<pre><code class=\"sql\">SELECT *\nFROM retail\nWHERE InvoiceNo = 536365\nLIMIT 2\n</code></pre>\n<p>Sample results</p>\n<pre><code>+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|     17850|United Kingdom|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nonly showing top 2 rows\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084972_246913372","id":"20190519-221114_648626738","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T14:17:39+0000","dateFinished":"2020-03-23T14:17:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:345"},{"text":"//Dataframe Filtering (where)\n\nretailCastDf.select(\"*\").where(\"InvoiceNo = 536365\").show(2)\n\n\n\n","user":"anonymous","dateUpdated":"2020-03-23T14:23:01+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\n|InvoiceNo|StockCode|         Description|Quantity|UnitPrice|CustomerID|       Country|to_timestamp(`InvoiceDate`, 'MM/dd/yyyy HH:mm')|\n+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|     2.55|     17850|United Kingdom|                            2010-12-01 08:26:00|\n|   536365|    71053| WHITE METAL LANTERN|       6|     3.39|     17850|United Kingdom|                            2010-12-01 08:26:00|\n+---------+---------+--------------------+--------+---------+----------+--------------+-----------------------------------------------+\nonly showing top 2 rows\n\n"}]},"apps":[],"jobName":"paragraph_1584860084972_-114612207","id":"20190519-201625_2028882244","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T14:23:01+0000","dateFinished":"2020-03-23T14:23:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:346"},{"user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584860084972_-1315586860","id":"20191007-145852_244125478","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:347"},{"text":"%md\n\n# DF Exercises\nIn the following phrargraphs, you will be asked to solve some bussiness question using Spark Dataframes. However, you can use Spark SQL to verify you solution. ","user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>DF Exercises</h1>\n<p>In the following phrargraphs, you will be asked to solve some bussiness question using Spark Dataframes. However, you can use Spark SQL to verify you solution.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084973_-22637163","id":"20190520-123428_698724288","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:348"},{"text":"//Spark SQL exercies\n//register retailCastDf as `retail` view\nretailCastDf.createOrReplaceTempView(\"retail\")\n\n//execute SQL\nspark.sql(\"SELECT * FROM retail limit 10\")","user":"anonymous","dateUpdated":"2020-03-23T14:30:56+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res72: org.apache.spark.sql.DataFrame = [InvoiceNo: string, StockCode: string ... 6 more fields]\n"}]},"apps":[],"jobName":"paragraph_1584860084973_1267940690","id":"20190520-142038_1683726413","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T14:30:56+0000","dateFinished":"2020-03-23T14:30:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:349"},{"text":"%md\n#### Q1: Find the top N largest invoices by the amount (`Quantity * UnitPrice`)\n\nNote: `InvoiceNo` will appear in multiple rows. <br>(e.g. a receipt can have multiple items on it.)\n\n**Sample output**\n```bash\n+---------+------------------+\n|InvoiceNo|            Amount|\n+---------+------------------+\n|   581483|          168469.6|\n|   541431|           77183.6|\n|   574941| 52940.93999999999|\n|   576365|50653.909999999996|\n|   556444|           38970.0|\n+---------+------------------+\n```","user":"anonymous","dateUpdated":"2020-03-23T16:29:28+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Q1: Find the top N largest invoices by the amount (<code>Quantity * UnitPrice</code>)</h4>\n<p>Note: <code>InvoiceNo</code> will appear in multiple rows. <br>(e.g. a receipt can have multiple items on it.)</p>\n<p><strong>Sample output</strong></p>\n<pre><code class=\"bash\">+---------+------------------+\n|InvoiceNo|            Amount|\n+---------+------------------+\n|   581483|          168469.6|\n|   541431|           77183.6|\n|   574941| 52940.93999999999|\n|   576365|50653.909999999996|\n|   556444|           38970.0|\n+---------+------------------+\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084973_-1346271711","id":"20190520-133812_405266917","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T16:29:28+0000","dateFinished":"2020-03-23T16:29:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:350"},{"text":"//top N largest invoices by amount\n\nretailCastDf.groupBy($\"InvoiceNo\").agg(sum($\"Quantity\" * $\"UnitPrice\").alias(\"Amount\")).orderBy($\"Amount\".desc).show(5)\n\n","user":"anonymous","dateUpdated":"2020-03-23T16:33:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+------------------+\n|InvoiceNo|            Amount|\n+---------+------------------+\n|   581483|          168469.6|\n|   541431|           77183.6|\n|   574941| 52940.93999999999|\n|   576365|50653.909999999996|\n|   556444|           38970.0|\n+---------+------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1584860084974_1746672910","id":"20190519-215312_1016690251","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T16:33:54+0000","dateFinished":"2020-03-23T16:33:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:351"},{"user":"anonymous","dateUpdated":"2020-03-22T06:54:44+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584860084974_-784974143","id":"20191007-145909_914572499","dateCreated":"2020-03-22T06:54:44+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:352"},{"text":"%md\n#### Q2: Find the top N largest invoices by the amount and show receipt details\n\n```\n+---------+------------------+-------------------+----------+--------------+\n|InvoiceNo|            Amount|        InvoiceDate|CustomerID|       Country|\n+---------+------------------+-------------------+----------+--------------+\n|   581483|          168469.6|2011-12-09 09:15:00|     16446|United Kingdom|\n|   541431|           77183.6|2011-01-18 10:01:00|     12346|United Kingdom|\n|   574941| 52940.93999999999|2011-11-07 17:42:00|      null|United Kingdom|\n|   576365|50653.909999999996|2011-11-14 17:55:00|      null|United Kingdom|\n|   556444|           38970.0|2011-06-10 15:28:00|     15098|United Kingdom|\n+---------+------------------+-------------------+----------+--------------+\n```","user":"anonymous","dateUpdated":"2020-03-23T16:38:57+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Q2: Find the top N largest invoices by the amount and show receipt details</h4>\n<pre><code>+---------+------------------+-------------------+----------+--------------+\n|InvoiceNo|            Amount|        InvoiceDate|CustomerID|       Country|\n+---------+------------------+-------------------+----------+--------------+\n|   581483|          168469.6|2011-12-09 09:15:00|     16446|United Kingdom|\n|   541431|           77183.6|2011-01-18 10:01:00|     12346|United Kingdom|\n|   574941| 52940.93999999999|2011-11-07 17:42:00|      null|United Kingdom|\n|   576365|50653.909999999996|2011-11-14 17:55:00|      null|United Kingdom|\n|   556444|           38970.0|2011-06-10 15:28:00|     15098|United Kingdom|\n+---------+------------------+-------------------+----------+--------------+\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084974_1937899607","id":"20190520-124355_215736883","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T16:38:57+0000","dateFinished":"2020-03-23T16:38:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:353"},{"text":"//N largest invoices by the amount and show receipt details\n\nval invoiceDf = retailCastDf.groupBy($\"InvoiceNo\",$\"InvoiceDate\",$\"CustomerID\",$\"Country\").agg(sum($\"Quantity\" * $\"UnitPrice\").alias(\"Amount\")).orderBy($\"Amount\".desc) \ninvoiceDf.select($\"InvoiceNo\", $\"Amount\",$\"InvoiceDate\",$\"CustomerID\",$\"Country\").show(5)\n","user":"anonymous","dateUpdated":"2020-03-23T17:37:24+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"invoiceDf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [InvoiceNo: string, InvoiceDate: timestamp ... 3 more fields]\n+---------+------------------+-------------------+----------+--------------+\n|InvoiceNo|            Amount|        InvoiceDate|CustomerID|       Country|\n+---------+------------------+-------------------+----------+--------------+\n|   581483|          168469.6|2011-12-09 09:15:00|     16446|United Kingdom|\n|   541431|           77183.6|2011-01-18 10:01:00|     12346|United Kingdom|\n|   574941| 52940.93999999999|2011-11-07 17:42:00|      null|United Kingdom|\n|   576365|50653.909999999996|2011-11-14 17:55:00|      null|United Kingdom|\n|   556444|           38970.0|2011-06-10 15:28:00|     15098|United Kingdom|\n+---------+------------------+-------------------+----------+--------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1584860084974_-104778181","id":"20190520-122626_1736024345","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T17:37:24+0000","dateFinished":"2020-03-23T17:37:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:354"},{"text":"%md\n#### Q3: For each country, find the top N largest invoices by the amount and show receipt details\n\nUse `Window functions` and `rank()` function\n\nReadings:\n- https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html\n- https://stackoverflow.com/questions/42966590/how-do-we-rank-dataframe\n- http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/\n- `Spark The Definitive Guide - page 134 - Windows Function`\n\n```\n+---------+------------------+-------------------+----------+---------+\n|InvoiceNo|            amount|        InvoiceDate|CustomerID|  Country|\n+---------+------------------+-------------------+----------+---------+\n|   571318| 5296.960000000001|2011-10-17 10:50:00|     17404|   Sweden|\n|   546530| 4400.280000000001|2011-03-14 13:25:00|     17404|   Sweden|\n|   571751|6068.0599999999995|2011-10-19 11:18:00|     12744|Singapore|\n|   548813|4037.7700000000004|2011-04-04 13:03:00|     12744|Singapore|\n|   552978| 9341.260000000004|2011-05-12 14:46:00|     12590|  Germany|\n|   564856|4257.0599999999995|2011-08-31 09:11:00|     12477|  Germany|\n|   571035|1002.3099999999998|2011-10-13 12:50:00|     12446|      RSA|\n|   573153| 8895.760000000004|2011-10-28 07:39:00|     12678|   France|\n|   570672| 4279.710000000004|2011-10-11 14:52:00|     12536|   France|\n|   541932|           2661.24|2011-01-24 11:39:00|     14439|   Greece|\n+---------+------------------+-------------------+----------+---------+\n```\n<br>\n<br>\n**Hints**:\n- At high level, you need to create a new column which indicates amount rank by country\n  - Use `Windows` function which partition by (\"Country\") and order by amount\n  - User `Rank()` function create a new `rank` column for each row\n  - filter out rows where `rank > 2`","user":"anonymous","dateUpdated":"2020-03-23T17:39:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":6,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Q3: For each country, find the top N largest invoices by the amount and show receipt details</h4>\n<p>Use <code>Window functions</code> and <code>rank()</code> function</p>\n<p>Readings:<br/>- <a href=\"https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html\">https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html</a><br/>- <a href=\"https://stackoverflow.com/questions/42966590/how-do-we-rank-dataframe\">https://stackoverflow.com/questions/42966590/how-do-we-rank-dataframe</a><br/>- <a href=\"http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/\">http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/</a><br/>- <code>Spark The Definitive Guide - page 134 - Windows Function</code></p>\n<pre><code>+---------+------------------+-------------------+----------+---------+\n|InvoiceNo|            amount|        InvoiceDate|CustomerID|  Country|\n+---------+------------------+-------------------+----------+---------+\n|   571318| 5296.960000000001|2011-10-17 10:50:00|     17404|   Sweden|\n|   546530| 4400.280000000001|2011-03-14 13:25:00|     17404|   Sweden|\n|   571751|6068.0599999999995|2011-10-19 11:18:00|     12744|Singapore|\n|   548813|4037.7700000000004|2011-04-04 13:03:00|     12744|Singapore|\n|   552978| 9341.260000000004|2011-05-12 14:46:00|     12590|  Germany|\n|   564856|4257.0599999999995|2011-08-31 09:11:00|     12477|  Germany|\n|   571035|1002.3099999999998|2011-10-13 12:50:00|     12446|      RSA|\n|   573153| 8895.760000000004|2011-10-28 07:39:00|     12678|   France|\n|   570672| 4279.710000000004|2011-10-11 14:52:00|     12536|   France|\n|   541932|           2661.24|2011-01-24 11:39:00|     14439|   Greece|\n+---------+------------------+-------------------+----------+---------+\n</code></pre>\n<br>\n<br>\n<p><strong>Hints</strong>:<br/>- At high level, you need to create a new column which indicates amount rank by country<br/> - Use <code>Windows</code> function which partition by (&ldquo;Country&rdquo;) and order by amount<br/> - User <code>Rank()</code> function create a new <code>rank</code> column for each row<br/> - filter out rows where <code>rank &gt; 2</code></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084975_2023043568","id":"20190520-150543_915955507","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T17:39:43+0000","dateFinished":"2020-03-23T17:39:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:355"},{"text":"//For each country, find the top N largest invoices by the amount and show receipt details\nimport org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.functions.row_number\n\ninvoiceDf.withColumn(\"rank\", row_number().over(Window.partitionBy($\"Country\").orderBy($\"Amount\".desc))).select($\"InvoiceNo\", $\"Amount\",$\"InvoiceDate\",$\"CustomerID\",$\"Country\").where($\"rank\"<=2).show(10)\n\n","user":"anonymous","dateUpdated":"2020-03-23T17:43:12+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.functions.row_number\n+---------+------------------+-------------------+----------+---------+\n|InvoiceNo|            Amount|        InvoiceDate|CustomerID|  Country|\n+---------+------------------+-------------------+----------+---------+\n|   571318| 5296.960000000001|2011-10-17 10:50:00|     17404|   Sweden|\n|   546530| 4400.280000000001|2011-03-14 13:25:00|     17404|   Sweden|\n|   571751|6068.0599999999995|2011-10-19 11:18:00|     12744|Singapore|\n|   548813|4037.7700000000004|2011-04-04 13:03:00|     12744|Singapore|\n|   552978| 9341.260000000004|2011-05-12 14:46:00|     12590|  Germany|\n|   564856|4257.0599999999995|2011-08-31 09:11:00|     12477|  Germany|\n|   571035|1002.3099999999998|2011-10-13 12:50:00|     12446|      RSA|\n|   573153| 8895.760000000004|2011-10-28 07:39:00|     12678|   France|\n|   570672| 4279.710000000004|2011-10-11 14:52:00|     12536|   France|\n|   541932|           2661.24|2011-01-24 11:39:00|     14439|   Greece|\n+---------+------------------+-------------------+----------+---------+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1584860084975_-1287286020","id":"20190520-125029_1350468290","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-23T17:43:12+0000","dateFinished":"2020-03-23T17:43:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:356"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584981937535_-860045824","id":"20200323-164537_42614939","dateCreated":"2020-03-23T16:45:37+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:357"},{"text":"%md\n\n#### Q4: Generate a daily and a weekly sales table and plot diagrams using Zeppelin built-in plot.\n\n\n```bash\ndailyDf.show(5)\n+-------------------+------------------+\n|              start|       sum(amount)|\n+-------------------+------------------+\n|2010-11-30 19:00:00|          58833.88|\n|2010-12-01 19:00:00| 45666.62999999999|\n|2010-12-02 19:00:00| 46161.11000000004|\n|2010-12-04 19:00:00|31383.949999999997|\n|2010-12-05 19:00:00| 53860.18000000004|\n+-------------------+------------------+\n```\n\n```bash\nweeklyDf.show(5)\n+-------------------+------------------+\n|              start|       sum(amount)|\n+-------------------+------------------+\n|2010-11-24 19:00:00| 58833.88000000002|\n|2010-12-01 19:00:00|         266320.76|\n|2010-12-08 19:00:00|234844.27999999997|\n|2010-12-15 19:00:00|177360.10999999993|\n|2010-12-22 19:00:00|11796.309999999992|\n+-------------------+------------------+\n```\n\nReadings\n- https://databricks.com/blog/2017/05/08/event-time-aggregation-watermarking-apache-sparks-structured-streaming.html\n- http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/","user":"anonymous","dateUpdated":"2020-03-24T00:42:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Q4: Generate a daily and a weekly sales table and plot diagrams using Zeppelin built-in plot.</h4>\n<pre><code class=\"bash\">dailyDf.show(5)\n+-------------------+------------------+\n|              start|       sum(amount)|\n+-------------------+------------------+\n|2010-11-30 19:00:00|          58833.88|\n|2010-12-01 19:00:00| 45666.62999999999|\n|2010-12-02 19:00:00| 46161.11000000004|\n|2010-12-04 19:00:00|31383.949999999997|\n|2010-12-05 19:00:00| 53860.18000000004|\n+-------------------+------------------+\n</code></pre>\n<pre><code class=\"bash\">weeklyDf.show(5)\n+-------------------+------------------+\n|              start|       sum(amount)|\n+-------------------+------------------+\n|2010-11-24 19:00:00| 58833.88000000002|\n|2010-12-01 19:00:00|         266320.76|\n|2010-12-08 19:00:00|234844.27999999997|\n|2010-12-15 19:00:00|177360.10999999993|\n|2010-12-22 19:00:00|11796.309999999992|\n+-------------------+------------------+\n</code></pre>\n<p>Readings<br/>- <a href=\"https://databricks.com/blog/2017/05/08/event-time-aggregation-watermarking-apache-sparks-structured-streaming.html\">https://databricks.com/blog/2017/05/08/event-time-aggregation-watermarking-apache-sparks-structured-streaming.html</a><br/>- <a href=\"http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/\">http://blog.madhukaraphatak.com/introduction-to-spark-two-part-5/</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1584860084975_-7042277","id":"20190520-140931_1510736707","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-24T00:42:46+0000","dateFinished":"2020-03-24T00:42:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:358"},{"text":"//Daily\n\nval dailyDf = invoiceDf.withWatermark(\"InvoiceDate\", \"1 days\").groupBy(window(invoiceDf.col(\"InvoiceDate\"),\"1 days\")).agg(sum($\"Amount\").as(\"daily_sum\")).sort($\"window.start\").select($\"window.start\",$\"daily_sum\")\ndailyDf.createOrReplaceTempView(\"dailySales\")\n\ndailyDf.show(5)","user":"anonymous","dateUpdated":"2020-03-24T01:24:09+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dailyDf: org.apache.spark.sql.DataFrame = [start: timestamp, daily_sum: double]\n+-------------------+------------------+\n|              start|         daily_sum|\n+-------------------+------------------+\n|2010-12-01 00:00:00| 58635.56000000002|\n|2010-12-02 00:00:00|46207.280000000006|\n|2010-12-03 00:00:00| 45620.46000000003|\n|2010-12-05 00:00:00|31383.950000000004|\n|2010-12-06 00:00:00| 53860.18000000004|\n+-------------------+------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1584860084976_1458714089","id":"20190520-181045_1661878813","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-24T01:24:09+0000","dateFinished":"2020-03-24T01:24:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:359"},{"text":"%sql\n-- Plot daily diagram here\nselect to_date(start), `daily_sum` from dailySales","user":"anonymous","dateUpdated":"2020-03-25T19:53:39+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"lineChart","height":326,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"start":"string","sum(amount)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"lineChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"stackedAreaChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"pieChart":{}},"commonSetting":{},"keys":[{"name":"to_date(dailysales.`start`)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"daily_sum","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"to_date(dailysales.`start`)\tdaily_sum\n2010-12-01\t58635.560000000005\n2010-12-02\t46207.280000000006\n2010-12-03\t45620.460000000014\n2010-12-05\t31383.950000000004\n2010-12-06\t53860.18000000002\n2010-12-07\t45059.05\n2010-12-08\t44189.839999999975\n2010-12-09\t52532.130000000005\n2010-12-10\t57404.91\n2010-12-12\t17240.919999999995\n2010-12-13\t35379.340000000004\n2010-12-14\t42843.29000000002\n2010-12-15\t29443.689999999995\n2010-12-16\t48334.350000000006\n2010-12-17\t43534.18999999998\n2010-12-19\t7517.3099999999995\n2010-12-20\t24741.749999999996\n2010-12-21\t47097.939999999995\n2010-12-22\t6134.57\n2010-12-23\t11796.309999999992\n2011-01-04\t14950.479999999994\n2011-01-05\t-1566.2299999999905\n2011-01-06\t37392.739999999976\n2011-01-07\t27233.14\n2011-01-09\t15710.799999999997\n2011-01-10\t24191.63999999999\n2011-01-11\t67817.12999999998\n2011-01-12\t23958.780000000006\n2011-01-13\t20533.540000000008\n2011-01-14\t47377.26\n2011-01-16\t7116.610000000001\n2011-01-17\t29256.00000000003\n2011-01-18\t18680.799999999985\n2011-01-19\t25585.810000000005\n2011-01-20\t17995.91\n2011-01-21\t31978.43999999999\n2011-01-23\t10285.95\n2011-01-24\t25555.620000000006\n2011-01-25\t27971.520000000008\n2011-01-26\t19493.31999999999\n2011-01-27\t21092.140000000003\n2011-01-28\t18567.77\n2011-01-30\t6456.4400000000005\n2011-01-31\t22364.649999999994\n2011-02-01\t28433.22\n2011-02-02\t21048.45\n2011-02-03\t23344.579999999998\n2011-02-04\t24994.169999999995\n2011-02-06\t3457.11\n2011-02-07\t25525.989999999998\n2011-02-08\t20728.14\n2011-02-09\t16692.580000000005\n2011-02-10\t13427.54\n2011-02-11\t20387.280000000002\n2011-02-13\t5535.400000000001\n2011-02-14\t26222.03\n2011-02-15\t36842.57999999999\n2011-02-16\t24730.809999999994\n2011-02-17\t26361.87\n2011-02-18\t15928.400000000003\n2011-02-20\t9578.89\n2011-02-21\t23807.83000000002\n2011-02-22\t32292.619999999995\n2011-02-23\t26792.760000000017\n2011-02-24\t22655.830000000005\n2011-02-25\t18029.840000000004\n2011-02-27\t9491.05\n2011-02-28\t21753.68000000001\n2011-03-01\t25471.709999999995\n2011-03-02\t18296.44999999999\n2011-03-03\t35842.62\n2011-03-04\t19474.87\n2011-03-06\t9596.23\n2011-03-07\t30525.580000000005\n2011-03-08\t25017.470000000005\n2011-03-09\t21907.120000000006\n2011-03-10\t25597.890000000007\n2011-03-11\t21995.28\n2011-03-13\t4137.62\n2011-03-14\t25864.590000000004\n2011-03-15\t20660.030000000002\n2011-03-16\t21182.64\n2011-03-17\t38804.249999999985\n2011-03-18\t16770.46\n2011-03-20\t21980.640000000003\n2011-03-21\t16370.27\n2011-03-22\t31312.350000000013\n2011-03-23\t24029.070000000007\n2011-03-24\t36562.100000000006\n2011-03-25\t30656.029999999995\n2011-03-27\t8979.98\n2011-03-28\t19207.030000000002\n2011-03-29\t70531.47\n2011-03-30\t31489.250000000007\n2011-03-31\t31004.079999999998\n2011-04-01\t24391.78000000001\n2011-04-03\t6878.1\n2011-04-04\t25073.020000000004\n2011-04-05\t28353.83\n2011-04-06\t17279.35\n2011-04-07\t18229.0\n2011-04-08\t23299.139999999992\n2011-04-10\t9363.88\n2011-04-11\t22110.309999999998\n2011-04-12\t25124.249999999996\n2011-04-13\t23898.2\n2011-04-14\t35295.57999999999\n2011-04-15\t28327.131000000005\n2011-04-17\t12704.3\n2011-04-18\t32185.610000000037\n2011-04-19\t23837.650000000005\n2011-04-20\t28239.390000000007\n2011-04-21\t31198.599999999995\n2011-04-26\t30585.539999999997\n2011-04-27\t25590.56000000001\n2011-04-28\t21241.9\n2011-05-01\t6964.660000000001\n2011-05-03\t19617.859999999997\n2011-05-04\t27462.300000000003\n2011-05-05\t28750.649999999994\n2011-05-06\t35714.58\n2011-05-08\t18808.92\n2011-05-09\t26060.430000000004\n2011-05-10\t45564.120000000024\n2011-05-11\t33240.36\n2011-05-12\t59911.97000000002\n2011-05-13\t30744.07\n2011-05-15\t9924.28\n2011-05-16\t25279.770000000008\n2011-05-17\t53603.829999999994\n2011-05-18\t34337.28999999999\n2011-05-19\t34348.75\n2011-05-20\t26256.51999999999\n2011-05-22\t24205.369999999995\n2011-05-23\t30739.55\n2011-05-24\t37028.91000000001\n2011-05-25\t24152.28\n2011-05-26\t33208.590000000004\n2011-05-27\t28232.190000000002\n2011-05-29\t7208.300000000001\n2011-05-31\t21967.959999999992\n2011-06-01\t20191.199999999997\n2011-06-02\t32502.00999999999\n2011-06-03\t16750.999999999996\n2011-06-05\t25520.35\n2011-06-06\t16791.39\n2011-06-07\t37644.30000000002\n2011-06-08\t42940.909999999974\n2011-06-09\t45515.749999999985\n2011-06-10\t22540.66\n2011-06-12\t12483.860000000004\n2011-06-13\t20372.92999999999\n2011-06-14\t40211.93000000001\n2011-06-15\t46139.17999999999\n2011-06-16\t34131.730000000025\n2011-06-17\t20800.719999999998\n2011-06-19\t22360.01000000001\n2011-06-20\t33493.39999999997\n2011-06-21\t22730.009999999995\n2011-06-22\t21794.94\n2011-06-23\t24273.310000000005\n2011-06-24\t8619.879999999992\n2011-06-26\t6175.169999999997\n2011-06-27\t16823.859999999993\n2011-06-28\t34704.64000000001\n2011-06-29\t21775.429999999993\n2011-06-30\t43834.55000000001\n2011-07-01\t13171.819999999998\n2011-07-03\t5977.140000000001\n2011-07-04\t44154.74999999999\n2011-07-05\t40334.97000000002\n2011-07-06\t26279.58\n2011-07-07\t31357.72000000001\n2011-07-08\t26840.08000000001\n2011-07-10\t5692.0700000000015\n2011-07-11\t22429.53\n2011-07-12\t25892.040000000005\n2011-07-13\t11612.05000000001\n2011-07-14\t32575.960000000006\n2011-07-15\t14478.930000000006\n2011-07-17\t17174.66\n2011-07-18\t28443.269999999997\n2011-07-19\t49316.78\n2011-07-20\t27305.41000000001\n2011-07-21\t30957.069999999996\n2011-07-22\t20015.23\n2011-07-24\t26476.199999999997\n2011-07-25\t26687.65\n2011-07-26\t21271.300999999996\n2011-07-27\t25568.450000000004\n2011-07-28\t55706.88000000002\n2011-07-29\t18094.209999999995\n2011-07-31\t33486.36\n2011-08-01\t21362.84\n2011-08-02\t14947.270000000004\n2011-08-03\t27075.020000000004\n2011-08-04\t61028.65\n2011-08-05\t21298.300000000003\n2011-08-07\t7464.120000000002\n2011-08-08\t19987.15\n2011-08-09\t26623.199999999997\n2011-08-10\t27474.219999999994\n2011-08-11\t72132.78999999998\n2011-08-12\t10049.480000000009\n2011-08-14\t5150.179999999999\n2011-08-15\t17205.54\n2011-08-16\t19103.710000000003\n2011-08-17\t49392.22\n2011-08-18\t53225.670000000006\n2011-08-19\t17248.540000000005\n2011-08-21\t14549.209999999997\n2011-08-22\t27978.410000000003\n2011-08-23\t25756.299999999996\n2011-08-24\t37074.899999999994\n2011-08-25\t22458.879999999994\n2011-08-26\t25550.229999999992\n2011-08-28\t10784.779999999997\n2011-08-30\t31640.900000000012\n2011-08-31\t16118.000000000005\n2011-09-01\t37296.6\n2011-09-02\t41745.07000000001\n2011-09-04\t17018.490000000005\n2011-09-05\t36844.04\n2011-09-06\t28052.62\n2011-09-07\t34125.649999999994\n2011-09-08\t26708.000000000007\n2011-09-09\t29317.690000000002\n2011-09-11\t35465.47\n2011-09-12\t29039.30999999999\n2011-09-13\t54828.450000000004\n2011-09-14\t23360.659999999993\n2011-09-15\t62943.810000000034\n2011-09-16\t25858.059999999994\n2011-09-18\t15692.329999999998\n2011-09-19\t46212.20999999998\n2011-09-20\t109286.20999999998\n2011-09-21\t42944.07000000001\n2011-09-22\t57076.83\n2011-09-23\t39426.479999999996\n2011-09-25\t31210.921\n2011-09-26\t28642.271000000004\n2011-09-27\t35752.16\n2011-09-28\t43383.03999999997\n2011-09-29\t43464.32999999998\n2011-09-30\t43992.85000000003\n2011-10-02\t11623.579999999998\n2011-10-03\t64214.78000000001\n2011-10-04\t48240.84000000003\n2011-10-05\t75244.42999999998\n2011-10-06\t55306.28\n2011-10-07\t47538.02000000002\n2011-10-09\t11922.240000000002\n2011-10-10\t44265.89000000002\n2011-10-11\t38267.75000000001\n2011-10-12\t29302.850000000006\n2011-10-13\t37067.17\n2011-10-14\t35225.54\n2011-10-16\t21605.440000000002\n2011-10-17\t47064.14\n2011-10-18\t44637.83999999999\n2011-10-19\t36003.42999999999\n2011-10-20\t60793.13999999999\n2011-10-21\t62961.26000000002\n2011-10-23\t12302.41\n2011-10-24\t38407.72000000003\n2011-10-25\t40807.490000000005\n2011-10-26\t37842.080000000016\n2011-10-27\t47480.15000000001\n2011-10-28\t39559.469999999994\n2011-10-30\t34545.28\n2011-10-31\t48475.44999999994\n2011-11-01\t28741.549999999996\n2011-11-02\t45239.06000000002\n2011-11-03\t62816.55000000001\n2011-11-04\t60081.76000000001\n2011-11-06\t42912.4\n2011-11-07\t70001.07999999996\n2011-11-08\t56647.66000000001\n2011-11-09\t62599.43000000001\n2011-11-10\t68956.24\n2011-11-11\t54835.51000000004\n2011-11-13\t33520.219999999994\n2011-11-14\t112141.10999999997\n2011-11-15\t60594.23000000003\n2011-11-16\t64408.7\n2011-11-17\t60329.719999999994\n2011-11-18\t48031.800000000025\n2011-11-20\t34902.01000000001\n2011-11-21\t48302.50000000002\n2011-11-22\t62307.32\n2011-11-23\t78480.70000000001\n2011-11-24\t48080.28000000001\n2011-11-25\t50442.72\n2011-11-27\t20571.49999999999\n2011-11-28\t55442.02000000003\n2011-11-29\t72219.20000000003\n2011-11-30\t59150.980000000025\n2011-12-01\t51410.94999999998\n2011-12-02\t57086.05999999999\n2011-12-04\t24565.78\n2011-12-05\t57751.32000000005\n2011-12-06\t54228.37000000003\n2011-12-07\t75076.22000000003\n2011-12-08\t81417.78000000001\n2011-12-09\t32131.530000000002\n"}]},"apps":[],"jobName":"paragraph_1584860084976_-2058864173","id":"20190520-140933_785400989","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-24T01:24:53+0000","dateFinished":"2020-03-24T01:25:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:360"},{"text":"//Weekly\n//write you DF solution here\nval weeklyDf = invoiceDf.withWatermark(\"InvoiceDate\", \"1 week\").groupBy(window(invoiceDf.col(\"InvoiceDate\"),\"1 week\")).agg(sum($\"Amount\").as(\"weekly_sum\")).sort($\"window.start\").select($\"window.start\",$\"weekly_sum\")\n\nweeklyDf.createOrReplaceTempView(\"weeklySales\")\n\nweeklyDf.show(5, truncate=false)\n\n//please verify using SparkSQL\n\n","user":"anonymous","dateUpdated":"2020-03-24T01:26:49+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"weeklyDf: org.apache.spark.sql.DataFrame = [start: timestamp, weekly_sum: double]\n+-------------------+------------------+\n|start              |weekly_sum        |\n+-------------------+------------------+\n|2010-11-25 00:00:00|58635.56000000002 |\n|2010-12-02 00:00:00|266320.76000000024|\n|2010-12-09 00:00:00|234844.2799999999 |\n|2010-12-16 00:00:00|177360.10999999996|\n|2010-12-23 00:00:00|11796.309999999992|\n+-------------------+------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1584860084977_644359676","id":"20190520-140933_428817963","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-24T01:26:49+0000","dateFinished":"2020-03-24T01:27:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:361"},{"text":"%sql\n-- Plot weekly diagram here\nselect to_date(start), `weekly_sum` from weeklySales","user":"anonymous","dateUpdated":"2020-03-25T19:53:40+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"lineChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"to_date(weeklysales.`start`)":"string","sum(amount)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"lineChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"to_date(weeklysales.`start`)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"weekly_sum","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"to_date(weeklysales.`start`)\tweekly_sum\n2010-11-25\t58635.560000000034\n2010-12-02\t266320.7600000002\n2010-12-09\t234844.27999999997\n2010-12-16\t177360.11000000002\n2010-12-23\t11796.309999999996\n2010-12-30\t13384.250000000002\n2011-01-06\t196304.23\n2011-01-13\t148550.0200000001\n2011-01-20\t133280.75999999998\n2011-01-27\t117962.67000000001\n2011-02-03\t114742.57000000005\n2011-02-10\t127145.63999999997\n2011-02-17\t134762.37\n2011-02-24\t115698.55999999994\n2011-03-03\t142363.89000000007\n2011-03-10\t119438.05\n2011-03-17\t149267.04000000007\n2011-03-24\t197425.86\n2011-03-31\t132980.16\n2011-04-07\t122024.77999999997\n2011-04-14\t160589.66100000014\n2011-04-21\t87374.7\n2011-04-28\t75286.71999999996\n2011-05-05\t188139.0599999999\n2011-05-12\t213801.21000000002\n2011-05-19\t176731.37999999992\n2011-05-26\t110808.24000000002\n2011-06-02\t172149.95999999996\n2011-06-09\t187264.3100000001\n2011-06-16\t155310.81000000006\n2011-06-23\t112372.29000000004\n2011-06-30\t173752.80999999997\n2011-07-07\t123823.48999999999\n2011-07-14\t169295.0100000001\n2011-07-21\t150975.9009999999\n2011-07-28\t170672.58\n2011-08-04\t163875.6400000001\n2011-08-11\t173033.91999999998\n2011-08-18\t175833.03\n2011-08-25\t106552.78999999998\n2011-09-01\t195082.46999999988\n2011-09-08\t198719.57999999987\n2011-09-15\t302936.69000000006\n2011-09-22\t235491.70199999982\n2011-09-29\t286780.8099999999\n2011-10-06\t226603.03000000003\n2011-10-13\t221603.5599999999\n2011-10-20\t253114.1\n2011-10-27\t244040.95999999982\n2011-11-03\t355058.87999999995\n2011-11-10\t394456.0100000001\n2011-11-17\t332354.05\n2011-11-24\t305906.7000000004\n2011-12-01\t320118.7000000002\n2011-12-08\t113549.31000000011\n"}]},"apps":[],"jobName":"paragraph_1584860084977_41836015","id":"20190520-212256_1274740776","dateCreated":"2020-03-22T06:54:44+0000","dateStarted":"2020-03-24T01:27:47+0000","dateFinished":"2020-03-24T01:28:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:362"},{"text":"%sql\n","user":"anonymous","dateUpdated":"2020-03-24T01:27:34+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1585013254592_-247484515","id":"20200324-012734_512936767","dateCreated":"2020-03-24T01:27:34+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:363"}],"name":"Jarvis/2-DataFrame_pub","id":"2F4Y9PFD4","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}